{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-13T18:08:44.053703400Z",
     "start_time": "2023-06-13T18:08:42.173031200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/linuxuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/linuxuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/linuxuser/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.helpers import get_project_dir\n",
    "from src.preprocessors import lemmatize_vocabulary, lemmatize_text\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PROJECT_PATH = get_project_dir()\n",
    "PATH_TO_VOCABULARY = os.path.join(PROJECT_PATH, 'data/vocabulary')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T18:08:52.761809600Z",
     "start_time": "2023-06-13T18:08:52.730459100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "###                      Lemmatazing vocabulary for titles                               ###\n",
    "print('+'+'-'*60)\n",
    "print('| Preprocessing MAIN vocabulary for titles ...')\n",
    "lemmatize_vocabulary(filename='voc_title.csv', path_to_vocabulary=PATH_TO_VOCABULARY)\n",
    "print('| Done')\n",
    "print('+'+'-'*60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "###                      Lemmatazing vocabulary for summaries                            ###\n",
    "print('+'+'-'*60)\n",
    "print('| Preprocessing MAIN vocabulary for summaries ...')\n",
    "lemmatize_vocabulary(filename='voc_summary.csv', path_to_vocabulary=PATH_TO_VOCABULARY)\n",
    "print('| Done')\n",
    "print('+'+'-'*60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "kwargs = {'path_to_read': os.path.join(PROJECT_PATH, 'data/preprocessed/'),\n",
    "          'path_to_write': os.path.join(PROJECT_PATH, 'data/preprocessed/'),\n",
    "          'path_to_vocabulary': os.path.join(PROJECT_PATH, 'data/vocabulary')}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T18:09:13.929084900Z",
     "start_time": "2023-06-13T18:09:13.897870800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "###                          Lemmatizing titles using vocabulary                           ###\n",
    "print('+'+'-'*60)\n",
    "print('| Lemmatazing MAIN titles ...')\n",
    "lemmatize_text(filename='title.csv', chunksize=50000, **kwargs)\n",
    "print('| Done')\n",
    "print('+'+'-'*60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------\n",
      "| Lemmatazing MAIN summaries ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "counting rows...: 3737451it [00:37, 99072.03it/s] \n",
      "CHUNKS: 100%|██████████| 75/75 [07:35<00:00,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Done\n",
      "+------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "###                          Lemmatizing summaries using vocabulary                        ###\n",
    "print('+'+'-'*60)\n",
    "print('| Lemmatazing MAIN summaries ...')\n",
    "lemmatize_text(filename='summary.csv', chunksize=50000, **kwargs)\n",
    "print('| Done')\n",
    "print('+'+'-'*60)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T18:18:27.854138900Z",
     "start_time": "2023-06-13T18:10:12.621236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
